import streamlit as st
from PIL import Image
import torch
import pandas as pd
import os,sys, io
#from pathlib import Path

# Define paths for all supporting files & dataset
# Check if the code is running in Colab
IN_COLAB = 'google.colab' in sys.modules

if not IN_COLAB:
    # Load environment variables from .env file
    from dotenv import load_dotenv
    load_dotenv()
    project_root = os.getenv('PROJECT_ROOT_PATH')
else:
    # Set the project root path for Colab
    project_root = userdata.get("project_root_path")

# Check if the project root path is set correctly
if project_root is None:
    raise ValueError("PROJECT_ROOT_PATH environment variable is not set.")

# Add the project root path to the system path
sys.path.append(project_root)

import app.predict as predict


# Define device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# Header configuration -> inputs 

st.title('üé® Artwork classifier')
st.info('This tool uses a selected deep learning model for classifying artwork into various styles and predicting whether it was created by a human artist or generated by AI.')

# Sidebar configuration -> inputs 

st.sidebar.write(f'## üõ†Ô∏è Setup Configuration')
st.sidebar.markdown("<hr>", unsafe_allow_html=True)
st.sidebar.write(f'#### 1. Select or upload image for analysis')

# Image Selection
img = st.sidebar.selectbox(
    'Select Image',
    ['', 
     'AI Surrealism', # correctly guess abstract ai generated art
     'AI Post Impressionism', # FALSE! struggles to identify between more abstract styles
     'AI Renaissance', # faces are a bit unreal
     'AI Realism', # pretty real image generated by AI and identified correctly
     'Human Realism', # correctly guess easily definable style (human)
     'Human Baroque', # correctly guess easily definable style (human)
     'Human Surrealism', # FALSE! probably better quality would lead to correct identification
     'Human Ukiyo' # correctly guess easily definable style (human)
     ],
     index = 0
)

# Image Upload
uploaded_file = st.sidebar.file_uploader("Upload Image", type=["png", "jpg"])

# Select Model
st.sidebar.write(f'#### 2. Select Classification Model')
classify_model = st.sidebar.selectbox(
    'Select Model',
    ['', 'CNN: baseline', 'ResNet18: base', 'ResNet18: with augmentation', 'ResNet18: best performance'], index = 0
)


# Main tabs configuration -> analysis & info

tab1,tab2,tab3,tab4 = st.tabs(['Classify Artwork', 'What is Art Classifier?', 'Models Description', 'Dataset Overview'])

# GitHub repository and release details
GITHUB_API_URL = "https://github.com/ovsvc/ADL-WS-2024/releases/download/v1/"


# Set up the tabs for classification
with tab1:

    # Prepaire functions
    # Function to convert PNG to JPG
    def convert_png_to_jpg(image: Image.Image) -> Image.Image:
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        return image
    

    # Proceed only if a model and image are selected
    if classify_model and (img or uploaded_file):


        # Map model names to github releases path
        model_mapping = {
            'CNN: baseline': '1.Simple_CNN.pth',
            'ResNet18: base': '2.ResNet18_base.pth',
            'ResNet18: with augmentation': '3.ResNet18_augmented.pth',
            'ResNet18: best performance': '4.ResNet18_best.pth'
        }

         # Create the correct model URL to download from GitHub
        model_url = f"{GITHUB_API_URL}{model_mapping[classify_model]}"  # Correct concatenation

        # Display selected model description
        st.markdown('#### üõ†Ô∏è Analysis Setup', unsafe_allow_html=True)
        st.write(f'##### 1. Model Selected - "{classify_model}"')

        # Add information about the selected model
        model_descriptions = {
            'CNN: baseline': 'A simple Convolutional Neural Network (CNN) model trained for artwork classification.',
            'ResNet18: base': 'A ResNet18 model, a deeper network architecture with residual connections, trained for artwork classification.',
            'ResNet18: with augmentation': 'A ResNet18 model trained with data augmentation techniques to improve generalization.',
            'ResNet18: best performance': 'A ResNet18 model trained with data augmentation & impoved image resolution to improve generalization.'
        }

        st.write(model_descriptions[classify_model])

        st.info("‚ùóÔ∏è If you want to read more about models -> go to 'Models Description' tab")

       # st.write('##### 2. Source image:')
       # image = Image.open(input_image)

        if img or uploaded_file:
            # If the image is selected from the sidebar, construct the file path and open
            if img:
                input_image = f"app/images/{img}.jpg"
                image = Image.open(input_image)
                st.write(f"Selected Image: {img}.jpg")
            # If a file is uploaded, read it and display
            elif uploaded_file:
                image_bytes = uploaded_file.read()  # Read the uploaded file into memory
                image = Image.open(io.BytesIO(image_bytes))  # Use BytesIO to open the image from memory
                st.write(f"Uploaded Image: {uploaded_file.name}")

        # If the image is in PNG format, convert it to JPG
        if image.format == 'PNG':
            image = convert_png_to_jpg(image)

        st.image(image, width=400)  # Display the selected image

        clicked = st.button('Analyze')

        st.markdown("<hr>", unsafe_allow_html=True)

        if clicked:

            # Load the selected model dynamically
            if classify_model == "CNN: baseline":
                type = "CNN"
            else:
                type = "ResNet18"

            model = predict.load_model(model_url, model_mapping[classify_model], type)  # Assuming your helper function handles this

            # Ensure the image is a PIL image before passing it to the model
            if isinstance(image, Image.Image):
                # Perform the classification on the image
                predicted_label, all_scores, heatmap_image, heatmap_data = predict.classify(model, image)

                # Convert it into a DataFrame for better table formatting
                df = pd.DataFrame(all_scores, columns=["Class Label", "Confidence Score"])
                df = df.reset_index(drop=True)
                df = df[:6]  # Display top 5 predictions
            else:
                st.write("Error: The uploaded image is not a valid format.")

            st.write('#### üìÑ Evaluation Results')
            
        

            # Show the image with the Grad-CAM heatmap overlay
            st.write(f'##### **1. Original Image with Grad-CAM Overlay**')
            st.image(heatmap_image, caption=f"Prediction: {predicted_label}",  width = 400)
            st.write(f' ‚ñ∂Ô∏è Heatmap shows features important for classification')

            st.markdown("---")
            # Display a message about the sorted class indices and confidence scores
            st.markdown('##### **2. Sorted Class Indices and Confidence Scores**')
            st.markdown("Here are the top 5 other labels with their confidence scores:")


            # Style the DataFrame and center the text for a better look
            st.markdown("""
                <style>
                    .stDataFrame thead th {
                        text-align: center;
                        font-weight: bold;
                        color: #2a2a2a;
                        background-color: #f5f5f5;
                    }
                    .stDataFrame tbody td {
                        text-align: center;
                        vertical-align: middle;
                        font-size: 14px;
                        padding: 8px;
                    }
                </style>
            """, unsafe_allow_html=True)

            # Display the DataFrame as an interactive table without the index column
            st.dataframe(df, hide_index=True)  # Exclude index column and center content

    else:
        st.write("Please select a model and an image to analyze using the sidebar. You can either select an image from available options or upload your own.")


# Specifying tab 2

with tab2:
    st.write("### What is Art Classifier?")
    
    st.markdown("""
    **Art Classifier** is an intelligent tool designed to analyze and classify artwork based on the image you provide.  
    Using deep learning models, it performs two primary classifications:
    
    - **Artwork Origin:** Determines whether the image was created by a human or generated by artificial intelligence.
    - **Artwork Style:** Classifies the image into one of **10 distinct artistic styles**:
        - Art nouveau
        - Baroque
        - Expressionism
        - Impressionism
        - Post impressionism
        - Realism
        - Renaissance
        - Romanticism
        - Surrealism
        - Ukiyo-e
    """)
    
    st.write("#### How It Works:")
    st.markdown("""
    1. **Upload or Select an Image:** Provide an image of the artwork you'd like to classify. This could be an uploaded file or one chosen from a pre-selected set.
    2. **Select a Model:** Choose from one of four pre-trained models, each fine-tuned for art classification.
    3. **Get Results:** The model processes your input and provides a detailed classification, helping you understand the origin and style of the artwork.
    """)



# Specifying tab 3
#'CNN: baseline', 'ResNet18: base', 'ResNet18: with augmentation', 'ResNet18: best performance'

with tab3:
    st.write("### What is the difference between models?")
    st.write(
        """
        This section provides a detailed comparison of the available models, including their architecture, 
        performance metrics, and the improvements made at each stage of development.
        """
    )
    
    st.write("---")  # Horizontal line
    # Description of the models
    st.write("#### 1. CNN: baseline ")
    st.write(
        """
        [View Notebook](https://github.com/ovsvc/ADL-WS-2024/blob/main/notebooks/1.%20Simple%20CNN%20%5Bbaseline%5D.ipynb)
       
        A lightweight convolutional neural network designed for image classification. It features:
        - Two convolutional layers with ReLU activation
        - Max pooling
        - A fully connected layer with 20 output units
         """
    )
    st.markdown(
        """
        **Performance Metrics:**
        - **Test Accuracy:** 45.12%
        - **Overall F1-Score:** 44.03%
        """
    )
    st.write("---")  # Horizontal line
    st.write("#### 2. ResNet18: base")
    st.write(
        """
        [View Notebook](https://github.com/ovsvc/ADL-WS-2024/blob/main/notebooks/2.%20ResNet%20%5Bbase%5D.ipynb)

        A residual neural network designed for image classification. It features:
        - A 7x7 convolutional layer with ReLU activation, followed by max pooling.
        - Four groups of residual blocks, each containing:
            - Two 3x3 convolutional layers with batch normalization and ReLU activation.
            - Shortcut connections that skip layers to ensure efficient gradient flow.
        - A global average pooling layer to reduce spatial dimensions.
        - A fully connected layer mapping to 20 output units (or as needed for specific tasks)

        This particular model is fine-tuned ResNet18 model with the following adjustments:
        - Pretrained weights loaded from ResNet-18 model
        - Layers ['conv1', 'bn1', 'layer1', 'layer2'] were frozen during training to focus on deeper feature extraction.
        """
    )
    st.markdown(
        """
        **Performance Metrics:**
        - **Test Accuracy:** 63.36%
        - **Overall F1-Score:** 63.21%
        """
    )

    st.write("---")  # Horizontal line
    st.write("#### 3. ResNet18: with augmentation")
    st.write(
        """
        [View Notebook](https://github.com/ovsvc/ADL-WS-2024/blob/main/notebooks/3.%20ResNet%20%5Baugmentation%5D.ipynb)
        
        The same ResNet18 architecture, enhanced with:
        - Data augmentation to prevent overfitting [Random Horizontal & Vertical Flips, Random Rotation]
        - Unfreezing of all layers for fine-tuning       
        """
    )
    st.markdown(
        """
        **Performance Metrics:**
        - **Test Accuracy:** 67.04%
        - **Overall F1-Score:** 66.56%
        """
    )
    st.write("---")  # Horizontal line
    st.write("#### 4. ResNet18: best performance")
    st.write(
        """
        [View Notebook](https://github.com/ovsvc/ADL-WS-2024/blob/main/notebooks/4.%20ResNet%20%5Bbest%20model%5D.ipynb)
        
        The final and most advanced model, with the following improvements:
        - Data augmentation to prevent overfitting [Random Horizontal & Vertical Flips, Random Rotation]
        - Increased image resolution to 224x224 to capture finer details
        - Fully unfrozen layers for maximum fine-tuning
        """
    )
    st.markdown(
        """
        **Performance Metrics:**
        - **Test Accuracy:** 82.90%
        - **Overall F1-Score:** 82.90%
        """
    )

    # Summary Section
    st.write("---")  # Horizontal line
    st.write("#### Model Selected")
    if classify_model:
        st.write(f"**{classify_model}**")
    else:
        st.write("You can now select preferred model using the sidebar on the left.")



with tab4:    
    st.write('#### Dataset Overview: AI-ArtBench')
    st.write("""
    The **AI-ArtBench** dataset is a large collection of art images, consisting of over **180,000 images**. 
    It includes **60,000 human-drawn artworks**, sourced directly from the ArtBench-10 dataset, and the remaining images are **AI-generated**, equally split between two types of generative models: **Latent Diffusion** and **Standard Diffusion**. 
    Additionally, the dataset includes various **art styles** that can be used to classify the images into different artistic categories.

    **Key Information:**
    - **Total Images**: 180,000+ art images.
    - **Human-Drawn Art**: 60,000 images from the ArtBench-10 dataset.
    - **AI-Generated Art**: Remaining images equally generated by Latent Diffusion and Standard Diffusion models.
    - **Resolution**: 
        - Human-drawn: 256x256.
        - Latent Diffusion: 256x256.
        - Standard Diffusion: 768x768.
    - **Art Styles**: 10 distinct artistic styles are represented in the dataset.
    - **Training/Test Split**: The dataset is already split into training and test subsets, making it easy to use for model training.

    #### Dataset Processing
    The dataset was pre-processed to balance the distribution of human and AI-generated artworks. Given that the number of AI-generated artworks was initially higher, the dataset was balanced by selecting **5,000 images per artistic style** for each creation type (human and AI). This resulted in a total of **100,000 images** for training.

    **Steps Taken:**
    1. Selected **5,000 images per artistic style** for both human and AI artworks.
    2. Split the dataset into **training** and **validation** sets with a **90/10 split**.
    3. Ensured **reproducibility** by setting a random seed.
    4. Resized all images to a uniform resolution of **256x256** for consistency.

    **Labeling Logic:**
    Each image was labeled using the format: 
    ```
    {AI/human}_{artistic_style_name}
    ```
    This structure ensures that the model can classify images based on both their **origin** (human vs AI) and **artistic style**.

    You can explore the dataset further at [AI-ArtBench on Kaggle](https://www.kaggle.com/datasets/ravidussilva/real-ai-art).
    """)
